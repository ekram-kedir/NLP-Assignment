# NLP-Assignment


This GitHub repository contains an Amharic N-gram language model that performs various tasks. It begins by generating n-grams for different lengths and illustrates the results with sample prints. The code then calculates the probabilities of these n-grams based on how often they appear in the text, highlighting the top 10 most likely n-grams for each length. Additionally, the repository delves into computing the likelihood of specific sentences and generating random sentences using n-grams, providing insight into how changing n values impacts the output.

To assess the model's performance, the repository conducts intrinsic evaluation by calculating perplexity on a validation set, enhancing the reliability of the evaluation. The evaluation scope expands with extrinsic methods, involving the training and testing of n-gram models on real Amharic text data. The repository ensures a solid foundation by incorporating comprehensive data cleaning and splitting procedures for subsequent tasks.
