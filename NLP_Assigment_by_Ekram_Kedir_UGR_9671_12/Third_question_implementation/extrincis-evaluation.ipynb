{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6995075,"sourceType":"datasetVersion","datasetId":4020760}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Function to remove symbols from the word\ndef remove_symbols(word):\n    return ''.join(char for char in word if (\n        ('\\u1200' <= char <= '\\u137C') and\n        (char not in ('\\u1362', '\\u1363', '\\u1366', '\\u1367', '\\u2018', '\\u2019', '\\u1364'))\n    ) or char.isspace())\n\n# Function to clean the text\ndef clean_text(line):\n    words = line.split() if len(line) > 1 else []\n    cleaned_words = [word for word in words if remove_symbols(word)]\n    return ' '.join(cleaned_words)\n\n# Load the labeled dataset for text classification (assuming the format is \"text \\t label\")\n# Replace 'your_dataset.txt' with the actual path and filename of your labeled dataset\ndataset_path = 'your_dataset.txt'\nwith open(dataset_path, 'r', encoding='utf-8') as file:\n    lines = file.readlines()\n\n# Split the lines into text and label\ndata = [line.strip().split('\\t') for line in lines if len(line.strip().split('\\t')) == 2]\n\n# Clean the text in the dataset\ndata = [(clean_text(text), label) for text, label in data]\n\n# Print the number of samples before the split\nprint(\"Number of samples before split:\", len(data))\n\n# Check if the dataset size is sufficient for the split\nif len(data) == 0:\n    raise ValueError(\"The dataset is empty. Please check your data cleaning process.\")\nelif len(data) < 5:\n    raise ValueError(\"The dataset is too small. Ensure you have enough labeled samples for training and validation.\")\n\n# Split the dataset into training and validation sets\ntrain_data, valid_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Extract text and labels for training\nX_train, y_train = zip(*train_data)\n\n# Extract text and labels for validation\nX_valid, y_valid = zip(*valid_data)\n\n# Vectorize the text using TF-IDF\nvectorizer = TfidfVectorizer()\nX_train = vectorizer.fit_transform(X_train)\nX_valid = vectorizer.transform(X_valid)\n\n# Train a simple text classifier (Naive Bayes in this example)\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)\n\n# Evaluate the classifier on the validation set\npredictions = classifier.predict(X_valid)\naccuracy = accuracy_score(y_valid, predictions)\n\nprint(f'Accuracy on Validation Set: {accuracy:.2f}')\n\n# Additional evaluation metrics\nprint('\\nClassification Report:')\nprint(classification_report(y_valid, predictions))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T18:30:32.500620Z","iopub.execute_input":"2023-11-22T18:30:32.501068Z"},"trusted":true},"execution_count":null,"outputs":[]}]}