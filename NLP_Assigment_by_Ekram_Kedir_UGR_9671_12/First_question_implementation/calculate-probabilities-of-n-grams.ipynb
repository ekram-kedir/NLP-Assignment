{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6995075,"sourceType":"datasetVersion","datasetId":4020760}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from collections import Counter\n\n# Remove symbols from the word\ndef remove_symbols(word):\n    return ''.join(char for char in word if (('\\u1200' <= char <= '\\u137C') and (char != '\\u1362') and (char != '\\u1363') and (char != '\\u1366')and (char != '\\u1367')and (char != '\\u2018')and (char != '\\u2019') and (char != '\\u1364')) or char.isspace())\n\n# Remove non-Amharic-alphabetic characters and symbols from words\ndef clean_text(line):\n    words = line.split()\n    cleaned_words = [word for word in words if remove_symbols(word)]\n    return ' '.join(cleaned_words)\n\n#Calculate the probability \ndef calculate_ngram_probabilities(file_path, n, top_k, batch_size=100000, encoding='utf-8'):\n    ngram_counts = Counter()\n\n    with open(file_path, 'r', encoding=encoding) as file:\n        for line in file:\n            cleaned_line = clean_text(line)\n            words = cleaned_line.strip().split()\n            ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n            ngram_counts.update(ngrams)\n\n    # Sort n-grams by frequency and take the top 10\n    top_ngrams = ngram_counts.most_common(top_k)\n\n    total_ngrams = sum(ngram_counts.values())\n\n    # Calculate probabilities for the top 10 n-grams\n    ngram_probabilities = {ngram: count / total_ngrams for ngram, count in top_ngrams}\n\n    return ngram_probabilities\n\n# Specify the path for our file\nfile_path = '/kaggle/input/nlp-assignment/GPAC.txt'\n\n# Print top 10 most likely n-grams for each n\nfor n in range(1, 5):\n    print(f'\\nTop 10 most likely {n}-grams:')\n    top_ngrams = calculate_ngram_probabilities(file_path, n, 10)\n    for ngram, probability in top_ngrams.items():\n        print(f'{ngram}: {probability:.6f}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-19T17:28:12.599973Z","iopub.execute_input":"2023-11-19T17:28:12.600953Z","iopub.status.idle":"2023-11-19T17:56:53.613538Z","shell.execute_reply.started":"2023-11-19T17:28:12.600898Z","shell.execute_reply":"2023-11-19T17:56:53.611524Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\nTop 10 most likely 1-grams:\nላይ: 0.009904\nነው: 0.009854\nውስጥ: 0.004538\nወደ: 0.004348\nእና: 0.004196\nጋር: 0.003833\nግን: 0.003509\nጊዜ: 0.003186\nነገር: 0.002827\nደግሞ: 0.002708\n\nTop 10 most likely 2-grams:\nዓ ም: 0.001237\nነገር ግን: 0.000563\nቀን ዓ: 0.000445\nአዲስ አበባ: 0.000396\nብቻ ሳይሆን: 0.000385\nምክር ቤት: 0.000309\nበአዲስ አበባ: 0.000302\nይሁን እንጂ: 0.000246\nየአዲስ አበባ: 0.000244\nጠቅላይ ሚኒስትር: 0.000244\n\nTop 10 most likely 3-grams:\nቀን ዓ ም: 0.000435\nእ ኤ አ: 0.000207\nዓ ም ጀምሮ: 0.000078\nተወካዮች ምክር ቤት: 0.000073\nበሌላ በኩል ደግሞ: 0.000065\nበ ዓ ም: 0.000064\nየአዲስ አበባ ከተማ: 0.000058\nበዓለም አቀፍ ደረጃ: 0.000054\nከጊዜ ወደ ጊዜ: 0.000052\nዓ/ም ኢሳት ዜና: 0.000052\n\nTop 10 most likely 4-grams:\nዓ ም ኢሳት ዜና: 0.000048\nመጋቢት ቀን ዓ ም: 0.000034\nየካቲት ቀን ዓ ም: 0.000033\nግንቦት ቀን ዓ ም: 0.000033\nሰኔ ቀን ዓ ም: 0.000030\nየአዲስ አበባ ከተማ አስተዳደር: 0.000029\nጥር ቀን ዓ ም: 0.000029\nጥቅምት ቀን ዓ ም: 0.000029\nበ የኔ ሃሳብ ዓምድ: 0.000027\nቀን ዓ ም ጀምሮ: 0.000027\n","output_type":"stream"}]}]}