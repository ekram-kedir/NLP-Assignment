{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6995075,"sourceType":"datasetVersion","datasetId":4020760}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport random\nfrom collections import Counter\n\ndef remove_symbols(word):\n    # Remove symbols from the word\n    return ''.join(char for char in word if '\\u1200' <= char <= '\\u137C' or char.isspace())\n\ndef clean_text(line):\n    # Remove non-Amharic-alphabetic characters and symbols from words\n    words = line.split()\n    cleaned_words = [remove_symbols(word) for word in words]\n    return ' '.join(cleaned_words)\n\ndef ngrams_model(line, n):\n    words = clean_text(line).strip().split()\n    # Generate n-grams\n    ngrams = tuple(zip(*[words[i:] for i in range(n)]))\n    return [' '.join(ngram) for ngram in ngrams]\n\ndef calculate_perplexity(ngram_model, validation_set, n):\n    total_log_prob = 0\n    total_tokens = 0\n\n    for ngram in validation_set:\n        total_tokens += 1\n        if (sum(ngram_model.values()) + len(ngram_model)) > 0:\n        # Calculate the log probability for each n-gram in the validation set\n            probability = (ngram_model[ngram] + 1) / (sum(ngram_model.values()) + len(ngram_model))\n\n        # Check if the probability is greater than 0 before taking the logarithm\n            if probability > 0:\n                log_prob = math.log(probability)\n            else:\n                log_prob = float('-inf')\n\n        # Sum the log probabilities for the entire validation set\n            total_log_prob += log_prob\n\n    # Calculate perplexity\n    perplexity = math.exp(-total_log_prob / total_tokens)\n\n    return perplexity\n\n# Specify the path for your file\nfile_path = '/kaggle/input/nlp-assignment/GPAC.txt'\n\n# Define the ratio for the split (e.g., 80% for training, 20% for validation)\ntrain_ratio = 0.8\n\n# Randomly shuffle the lines of the corpus\nwith open(file_path, 'r', encoding='utf-8') as file:\n    amharic_corpus = file.readlines()\n\nrandom.shuffle(amharic_corpus)\n\n# Split the corpus into training and validation sets\nsplit_idx = int(len(amharic_corpus) * train_ratio)\ntrain_set = amharic_corpus[:split_idx]\nval_set = amharic_corpus[split_idx:]\n\n# Train an n-gram language model on the training set line by line\nn_value = 2  # Adjust based on the desired value of n for the n-gram model\nngram_model = Counter()\n\n# Process training set line by line\nfor line in train_set:\n    ngram_model.update(ngrams_model(line, n_value))\n\n# Calculate perplexity on the validation set line by line\nval_perplexity = calculate_perplexity(ngram_model, [tuple(ngrams_model(line, n_value)) for line in val_set], n_value)\n\nprint(f'Perplexity on the validation set: {val_perplexity:.6f}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-19T17:58:38.792033Z","iopub.execute_input":"2023-11-19T17:58:38.794329Z","iopub.status.idle":"2023-11-19T18:01:23.469493Z","shell.execute_reply.started":"2023-11-19T17:58:38.794272Z","shell.execute_reply":"2023-11-19T18:01:23.467832Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Perplexity on the validation set: 1.000000\n","output_type":"stream"}]}]}